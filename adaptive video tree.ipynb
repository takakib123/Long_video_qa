{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installations\n",
    "\n",
    "This section prepares the environment by cloning necessary repositories and installing Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/ludoplayer69/videotree\n",
    "!git clone https://github.com/facebookresearch/perception_models.git\n",
    "!git clone https://github.com/subhadarship/kmeans_pytorch\n",
    "\n",
    "!pip install -q -U bitsandbytes accelerate transformers\n",
    "!pip install -q gdown decord ftfy groq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "All key parameters for the pipeline are defined here. Modify this section to change model settings, paths, and hyperparameters for experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T04:32:19.191362Z",
     "iopub.status.busy": "2025-08-23T04:32:19.190791Z",
     "iopub.status.idle": "2025-08-23T04:32:21.918716Z",
     "shell.execute_reply": "2025-08-23T04:32:21.918005Z",
     "shell.execute_reply.started": "2025-08-23T04:32:19.191332Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "# Set your Groq API key here\n",
    "# Get one from https://console.groq.com/keys\n",
    "os.environ[\"GROQ_API_KEY\"] = \"  \"\n",
    "\n",
    "# To prevent CUDA memory fragmentation\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "class PipelineConfig:\n",
    "    # General\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    MAX_VIDEOS_TO_PROCESS = 10  # Limit the number of videos for a quick run\n",
    "\n",
    "    # Paths\n",
    "    WORK_DIR = Path('/kaggle/working/')\n",
    "    DATA_DIR = Path('/kaggle/input/egoschema/')\n",
    "    \n",
    "    # Derived Paths\n",
    "    VIDEO_DIR = WORK_DIR / 'downloaded_videos'\n",
    "    FRAMES_DIR = WORK_DIR / 'extracted_frames'\n",
    "    FEATURES_DIR = WORK_DIR / 'extracted_features'\n",
    "    OUTPUTS_DIR = WORK_DIR / 'outputs'\n",
    "    \n",
    "    # Data sources\n",
    "    DRIVE_IDS_JSON = WORK_DIR / 'videotree/drive_ids.json'\n",
    "    ANNOTATIONS_JSON = DATA_DIR / 'fullset_anno.json'\n",
    "    CAPTIONS_JSON = DATA_DIR / 'blip2_fullset.json'\n",
    "\n",
    "    # Feature Extraction\n",
    "    FRAME_EXTRACTION_FPS = 1\n",
    "    PERCEPTION_MODEL_NAME = 'PE-Core-B16-224'\n",
    "\n",
    "    # Width Expansion (Adaptive Clustering)\n",
    "    GROQ_MODEL = 'llama-3.1-8b-instant'\n",
    "    MAX_CLUSTER_NUM = 32\n",
    "    INIT_CLUSTER_NUM = 4\n",
    "    RELEVANCE_THRESHOLD = 5  # Stop clustering if >= this many high-relevance frames are found\n",
    "\n",
    "    # Depth Expansion (Hierarchical Clustering)\n",
    "    NUM_SUBCLUSTERS = 4\n",
    "    NUM_SUB_SUBCLUSTERS = 4\n",
    "\n",
    "    # VLM Inference\n",
    "    VLM_MODEL_ID = \"unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit\"\n",
    "    VLM_BATCH_SIZE = 10 # Lower if you encounter Out-of-Memory errors\n",
    "\n",
    "    def __init__(self):\n",
    "        # Create all necessary directories\n",
    "        for path in [self.WORK_DIR, self.VIDEO_DIR, self.FRAMES_DIR, \n",
    "                     self.FEATURES_DIR, self.OUTPUTS_DIR]:\n",
    "            path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "config = PipelineConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Imports and Utility Functions\n",
    "\n",
    "This section contains all required imports and helper functions used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T04:32:22.135098Z",
     "iopub.status.busy": "2025-08-23T04:32:22.134677Z",
     "iopub.status.idle": "2025-08-23T04:32:31.974045Z",
     "shell.execute_reply": "2025-08-23T04:32:31.973359Z",
     "shell.execute_reply.started": "2025-08-23T04:32:22.135070Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-23 04:32:25.595644: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755923545.621196     259 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755923545.629207     259 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import cv2\n",
    "import re\n",
    "import gdown\n",
    "import string\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "from groq import Groq\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "# Add cloned repos to system path for imports\n",
    "sys.path.append(str(config.WORK_DIR / 'perception_models'))\n",
    "sys.path.append(str(config.WORK_DIR / 'kmeans_pytorch'))\n",
    "from kmeans_pytorch import kmeans\n",
    "\n",
    "# --- Generic Utilities ---\n",
    "def load_json(file_path: Path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(data, file_path: Path, indent=4):\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f, indent=indent)\n",
    "        \n",
    "def _numeric_sort_key(p: Path):\n",
    "    try:\n",
    "        return int(p.stem)\n",
    "    except ValueError:\n",
    "        return p.stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation\n",
    "\n",
    "Downloads videos from Google Drive and loads the corresponding questions and captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T04:32:31.976058Z",
     "iopub.status.busy": "2025-08-23T04:32:31.975409Z",
     "iopub.status.idle": "2025-08-23T04:32:52.657849Z",
     "shell.execute_reply": "2025-08-23T04:32:52.657011Z",
     "shell.execute_reply.started": "2025-08-23T04:32:31.976034Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Data Preparation ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Videos: 100%|██████████| 10/10 [00:20<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 videos with corresponding questions.\n"
     ]
    }
   ],
   "source": [
    "def download_videos(drive_json_path: Path, save_path: Path, max_downloads: int):\n",
    "    if not drive_json_path.exists():\n",
    "        print(f\"[ERROR] Drive IDs JSON not found at: {drive_json_path}\")\n",
    "        return\n",
    "        \n",
    "    drive_data = load_json(drive_json_path)\n",
    "    video_ids_to_download = list(drive_data.items())[:max_downloads]\n",
    "    \n",
    "    for uuid, drive_id in tqdm(video_ids_to_download, desc=\"Downloading Videos\"):\n",
    "        output_file = save_path / f\"{uuid}.mp4\"\n",
    "        if not output_file.exists(): # Skip if already downloaded\n",
    "            gdown.download(id=drive_id, output=str(output_file), quiet=True)\n",
    "\n",
    "def load_metadata(config: PipelineConfig):\n",
    "    video_ids = [p.stem for p in config.VIDEO_DIR.glob(\"*.mp4\")]\n",
    "    annotations = load_json(config.ANNOTATIONS_JSON)\n",
    "    captions = load_json(config.CAPTIONS_JSON)\n",
    "    \n",
    "    questions = {}\n",
    "    for vid in video_ids:\n",
    "        if vid not in annotations:\n",
    "            continue\n",
    "        \n",
    "        anno = annotations[vid]\n",
    "        option_keys = sorted([k for k in anno if k.startswith(\"option \")], key=lambda x: int(x.split()[1]))\n",
    "        \n",
    "        prompt = f\"Question:\\n{anno['question']}\\n\\nOptions:\\n\"\n",
    "        for letter, key in zip(string.ascii_uppercase, option_keys):\n",
    "            prompt += f\"{letter}. {anno[key]}\\n\"\n",
    "        prompt += \"\\nPlease choose the most appropriate answer (A–E).\"\n",
    "        questions[vid] = prompt\n",
    "        \n",
    "    return video_ids, questions, captions\n",
    "\n",
    "# Execute Data Preparation\n",
    "print(\"--- Starting Data Preparation ---\")\n",
    "download_videos(config.DRIVE_IDS_JSON, config.VIDEO_DIR, config.MAX_VIDEOS_TO_PROCESS)\n",
    "video_ids, questions, captions = load_metadata(config)\n",
    "print(f\"Found {len(video_ids)} videos with corresponding questions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Module 1: Feature Extraction\n",
    "\n",
    "Extracts frames from videos and computes feature embeddings using a pre-trained perception model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T04:32:52.659415Z",
     "iopub.status.busy": "2025-08-23T04:32:52.658793Z",
     "iopub.status.idle": "2025-08-23T04:34:26.435095Z",
     "shell.execute_reply": "2025-08-23T04:34:26.434276Z",
     "shell.execute_reply.started": "2025-08-23T04:32:52.659382Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Feature Extraction ---\n",
      "Missing keys for loading model: []\n",
      "Unexpected keys for loading model: []\n",
      "Feature extraction model loaded.\n",
      "Extracting frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Frames: 100%|██████████| 10/10 [00:40<00:00,  4.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   0%|          | 0/10 [00:00<?, ?it/s]/tmp/ipykernel_259/3067077015.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Extracting Features: 100%|██████████| 10/10 [00:38<00:00,  3.87s/it]\n"
     ]
    }
   ],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self, config: PipelineConfig):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.preprocess = None\n",
    "\n",
    "    def _load_model(self):\n",
    "        if self.model is not None and self.preprocess is not None:\n",
    "            return\n",
    "        \n",
    "        # The model code expects to be run from its own directory\n",
    "        cwd = os.getcwd()\n",
    "        os.chdir(self.config.WORK_DIR / 'perception_models')\n",
    "        import core.vision_encoder.pe as pe\n",
    "        import core.vision_encoder.transforms as transforms\n",
    "        \n",
    "        self.model = pe.CLIP.from_config(self.config.PERCEPTION_MODEL_NAME, pretrained=True).to(self.config.DEVICE).eval()\n",
    "        self.preprocess = transforms.get_image_transform(self.model.image_size)\n",
    "        \n",
    "        os.chdir(cwd)\n",
    "        print(\"Feature extraction model loaded.\")\n",
    "\n",
    "    def _extract_frames_for_video(self, video_path: Path):\n",
    "        out_dir = self.config.FRAMES_DIR / video_path.stem\n",
    "        out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        cap = cv2.VideoCapture(str(video_path))\n",
    "        if not cap.isOpened(): return\n",
    "\n",
    "        fps_ori = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "        frame_interval = max(1, int(fps_ori // self.config.FRAME_EXTRACTION_FPS))\n",
    "        \n",
    "        count = 0\n",
    "        success, img = cap.read()\n",
    "        while success:\n",
    "            if count % frame_interval == 0:\n",
    "                cv2.imwrite(str(out_dir / f\"{count}.jpg\"), img)\n",
    "            success, img = cap.read()\n",
    "            count += 1\n",
    "        cap.release()\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def _extract_features_for_dir(self, frames_dir: Path):\n",
    "        if not frames_dir.exists(): return\n",
    "\n",
    "        image_files = sorted(list(frames_dir.glob('*.jpg')), key=_numeric_sort_key)\n",
    "        if not image_files: return\n",
    "\n",
    "        feats_list = []\n",
    "        for img_fp in image_files:\n",
    "            img = Image.open(img_fp).convert('RGB')\n",
    "            inp = self.preprocess(img).unsqueeze(0).to(self.config.DEVICE)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                feat = self.model.encode_image(inp)\n",
    "            feats_list.append(feat)\n",
    "            \n",
    "        stacked_feats = torch.cat(feats_list, dim=0)\n",
    "        torch.save(stacked_feats, self.config.FEATURES_DIR / f\"{frames_dir.name}.pt\")\n",
    "\n",
    "    def run(self, video_ids: list[str]):\n",
    "        self._load_model()\n",
    "        \n",
    "        print(\"Extracting frames...\")\n",
    "        for video_id in tqdm(video_ids, desc=\"Extracting Frames\"):\n",
    "            video_path = self.config.VIDEO_DIR / f\"{video_id}.mp4\"\n",
    "            self._extract_frames_for_video(video_path)\n",
    "\n",
    "        print(\"Extracting features...\")\n",
    "        for video_id in tqdm(video_ids, desc=\"Extracting Features\"):\n",
    "            frames_dir = self.config.FRAMES_DIR / video_id\n",
    "            self._extract_features_for_dir(frames_dir)\n",
    "\n",
    "# Execute Feature Extraction\n",
    "print(\"--- Starting Feature Extraction ---\")\n",
    "feature_extractor = FeatureExtractor(config)\n",
    "feature_extractor.run(video_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Module 2: Width Expansion (Adaptive Clustering)\n",
    "\n",
    "Applies k-means clustering to the frame features. An LLM (via Groq) scores the relevance of representative frames to iteratively find the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T04:34:26.437358Z",
     "iopub.status.busy": "2025-08-23T04:34:26.437075Z",
     "iopub.status.idle": "2025-08-23T04:38:04.791093Z",
     "shell.execute_reply": "2025-08-23T04:38:04.790186Z",
     "shell.execute_reply.started": "2025-08-23T04:34:26.437305Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Width Expansion (Adaptive Clustering) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos (Width):   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=188.140259, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00,  3.90it/s, center_shift=188.140259, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00,  3.90it/s, center_shift=6.656952, iteration=2, tol=0.000100]  \u001b[A\n",
      "[running kmeans]: 2it [00:00,  3.90it/s, center_shift=2.033382, iteration=3, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 3it [00:00,  3.90it/s, center_shift=0.353337, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 4it [00:00,  3.90it/s, center_shift=0.139455, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 6it [00:00, 21.00it/s, center_shift=0.000000, iteration=6, tol=0.000100]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=538.343384, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 126.02it/s, center_shift=11.064881, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 166.90it/s, center_shift=5.948859, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 3it [00:00, 187.88it/s, center_shift=1.407595, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 4it [00:00, 200.73it/s, center_shift=2.239845, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 207.25it/s, center_shift=2.057570, iteration=6, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 6it [00:00, 209.96it/s, center_shift=1.048385, iteration=7, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 7it [00:00, 214.48it/s, center_shift=0.268548, iteration=8, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 9it [00:00, 232.70it/s, center_shift=0.000000, iteration=9, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=1389.674927, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 103.63it/s, center_shift=31.922663, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 133.11it/s, center_shift=4.012420, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 3it [00:00, 149.56it/s, center_shift=6.055304, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 4it [00:00, 158.85it/s, center_shift=0.294459, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 165.73it/s, center_shift=0.043747, iteration=6, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 6it [00:00, 170.71it/s, center_shift=0.039437, iteration=7, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 7it [00:00, 174.66it/s, center_shift=0.155348, iteration=8, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 8it [00:00, 177.75it/s, center_shift=0.040769, iteration=9, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 9it [00:00, 179.52it/s, center_shift=0.036466, iteration=10, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 10it [00:00, 181.78it/s, center_shift=0.104478, iteration=11, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 11it [00:00, 183.40it/s, center_shift=0.237875, iteration=12, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 12it [00:00, 184.44it/s, center_shift=0.671621, iteration=13, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 13it [00:00, 185.26it/s, center_shift=0.570918, iteration=14, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 14it [00:00, 186.10it/s, center_shift=1.573035, iteration=15, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 15it [00:00, 187.39it/s, center_shift=1.143038, iteration=16, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 16it [00:00, 188.62it/s, center_shift=0.382035, iteration=17, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 18it [00:00, 196.50it/s, center_shift=0.000000, iteration=18, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=4606.518555, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 70.72it/s, center_shift=18.780474, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 93.48it/s, center_shift=2.821367, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 3it [00:00, 103.57it/s, center_shift=1.239353, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 4it [00:00, 110.46it/s, center_shift=0.355974, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 114.23it/s, center_shift=0.289929, iteration=6, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 7it [00:00, 131.79it/s, center_shift=0.000000, iteration=7, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Videos (Width):  10%|█         | 1/10 [00:03<00:29,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=321.375336, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 180.32it/s, center_shift=17.444477, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 217.78it/s, center_shift=2.592755, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 3it [00:00, 234.81it/s, center_shift=1.513756, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 4it [00:00, 243.63it/s, center_shift=0.396854, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 250.69it/s, center_shift=0.131118, iteration=6, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 7it [00:00, 273.82it/s, center_shift=0.000000, iteration=7, tol=0.000100]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=1020.801575, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 142.74it/s, center_shift=15.772219, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 182.41it/s, center_shift=4.262739, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 3it [00:00, 201.70it/s, center_shift=7.017419, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 4it [00:00, 210.90it/s, center_shift=0.872046, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 214.47it/s, center_shift=1.449256, iteration=6, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 6it [00:00, 217.28it/s, center_shift=2.711781, iteration=7, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 7it [00:00, 216.84it/s, center_shift=2.088401, iteration=8, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 8it [00:00, 219.81it/s, center_shift=0.498171, iteration=9, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 10it [00:00, 232.53it/s, center_shift=0.000000, iteration=10, tol=0.000100][A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=3377.533447, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 105.65it/s, center_shift=51.638443, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 137.56it/s, center_shift=38.048801, iteration=3, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 3it [00:00, 154.53it/s, center_shift=9.550435, iteration=4, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 4it [00:00, 166.03it/s, center_shift=1.536264, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 171.80it/s, center_shift=4.646233, iteration=6, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 6it [00:00, 176.68it/s, center_shift=1.812606, iteration=7, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 7it [00:00, 178.79it/s, center_shift=1.395089, iteration=8, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 8it [00:00, 179.38it/s, center_shift=0.960055, iteration=9, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 9it [00:00, 180.53it/s, center_shift=3.291580, iteration=10, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 11it [00:00, 191.30it/s, center_shift=0.000000, iteration=11, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=9640.849609, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 73.99it/s, center_shift=67.970192, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 93.31it/s, center_shift=28.737940, iteration=3, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 3it [00:00, 104.44it/s, center_shift=1.732220, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 4it [00:00, 110.13it/s, center_shift=1.007924, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 6it [00:00, 131.35it/s, center_shift=0.000000, iteration=6, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Videos (Width):  20%|██        | 2/10 [00:07<00:28,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=463.414368, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 165.25it/s, center_shift=12.491178, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 211.14it/s, center_shift=4.822322, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 3it [00:00, 233.51it/s, center_shift=4.039855, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 4it [00:00, 240.18it/s, center_shift=1.473219, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 248.19it/s, center_shift=0.414318, iteration=6, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 6it [00:00, 255.31it/s, center_shift=1.148929, iteration=7, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 7it [00:00, 262.21it/s, center_shift=0.136464, iteration=8, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 8it [00:00, 266.41it/s, center_shift=0.129773, iteration=9, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 9it [00:00, 270.67it/s, center_shift=0.110136, iteration=10, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 11it [00:00, 285.71it/s, center_shift=0.000000, iteration=11, tol=0.000100]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=1793.734985, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 136.31it/s, center_shift=139.356033, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 175.17it/s, center_shift=69.361763, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 3it [00:00, 187.94it/s, center_shift=50.438812, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 4it [00:00, 198.75it/s, center_shift=9.054205, iteration=5, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 5it [00:00, 202.94it/s, center_shift=3.646073, iteration=6, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 6it [00:00, 208.86it/s, center_shift=0.218852, iteration=7, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 8it [00:00, 228.16it/s, center_shift=0.000000, iteration=8, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=3391.110840, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 111.83it/s, center_shift=41.664131, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 144.71it/s, center_shift=15.856494, iteration=3, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 3it [00:00, 154.51it/s, center_shift=1.387201, iteration=4, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 5it [00:00, 186.81it/s, center_shift=0.000000, iteration=5, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=13793.071289, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 70.21it/s, center_shift=115.675385, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 92.06it/s, center_shift=58.226871, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 3it [00:00, 99.21it/s, center_shift=8.251153, iteration=4, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 5it [00:00, 125.08it/s, center_shift=0.000000, iteration=5, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Videos (Width):  30%|███       | 3/10 [00:12<00:30,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=262.762268, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 162.27it/s, center_shift=14.912267, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 203.56it/s, center_shift=0.605691, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 3it [00:00, 220.63it/s, center_shift=0.423645, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 4it [00:00, 231.30it/s, center_shift=0.055259, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 6it [00:00, 258.11it/s, center_shift=0.000000, iteration=6, tol=0.000100]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=975.380066, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 139.01it/s, center_shift=30.399158, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 182.99it/s, center_shift=6.667058, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 3it [00:00, 202.58it/s, center_shift=0.747641, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 241.03it/s, center_shift=0.000000, iteration=5, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=3085.843018, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 102.21it/s, center_shift=96.599762, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 134.53it/s, center_shift=29.260267, iteration=3, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 3it [00:00, 150.20it/s, center_shift=0.502125, iteration=4, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 4it [00:00, 160.13it/s, center_shift=0.361889, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 166.15it/s, center_shift=0.299426, iteration=6, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 6it [00:00, 170.64it/s, center_shift=0.850568, iteration=7, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 7it [00:00, 174.67it/s, center_shift=0.124626, iteration=8, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 8it [00:00, 178.05it/s, center_shift=1.066220, iteration=9, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 9it [00:00, 180.29it/s, center_shift=0.088493, iteration=10, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 11it [00:00, 191.89it/s, center_shift=0.000000, iteration=11, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=6622.844238, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 81.08it/s, center_shift=121.904297, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 102.10it/s, center_shift=2.852664, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 3it [00:00, 112.29it/s, center_shift=0.340378, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 138.03it/s, center_shift=0.000000, iteration=5, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Videos (Width):  40%|████      | 4/10 [00:35<01:10, 11.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=209.821259, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 163.09it/s, center_shift=3.515565, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 209.32it/s, center_shift=2.525043, iteration=3, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 3it [00:00, 233.22it/s, center_shift=3.609009, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 4it [00:00, 249.22it/s, center_shift=1.853347, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 258.96it/s, center_shift=1.144781, iteration=6, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 6it [00:00, 266.59it/s, center_shift=0.039114, iteration=7, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 7it [00:00, 271.05it/s, center_shift=0.040561, iteration=8, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 9it [00:00, 289.20it/s, center_shift=0.000000, iteration=9, tol=0.000100]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=822.633667, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 135.33it/s, center_shift=59.755886, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 178.21it/s, center_shift=13.300785, iteration=3, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 3it [00:00, 197.32it/s, center_shift=2.555480, iteration=4, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 4it [00:00, 207.48it/s, center_shift=1.132269, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 6it [00:00, 237.49it/s, center_shift=0.000000, iteration=6, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=2232.361328, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 106.03it/s, center_shift=37.831345, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 140.80it/s, center_shift=0.279432, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 4it [00:00, 186.68it/s, center_shift=0.000000, iteration=4, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=7447.219238, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 67.71it/s, center_shift=49.606190, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 90.65it/s, center_shift=0.800744, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 4it [00:00, 126.92it/s, center_shift=0.000000, iteration=4, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Videos (Width):  50%|█████     | 5/10 [01:06<01:33, 18.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=324.727020, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 158.63it/s, center_shift=9.744284, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 207.85it/s, center_shift=4.176831, iteration=3, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 3it [00:00, 231.04it/s, center_shift=1.482144, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 4it [00:00, 243.55it/s, center_shift=0.740228, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 251.14it/s, center_shift=0.299111, iteration=6, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 6it [00:00, 254.60it/s, center_shift=0.139624, iteration=7, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 7it [00:00, 258.54it/s, center_shift=0.139928, iteration=8, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 8it [00:00, 260.93it/s, center_shift=0.186372, iteration=9, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 9it [00:00, 262.39it/s, center_shift=0.151171, iteration=10, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 10it [00:00, 267.07it/s, center_shift=0.068888, iteration=11, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 11it [00:00, 269.71it/s, center_shift=0.095540, iteration=12, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 12it [00:00, 269.13it/s, center_shift=0.069962, iteration=13, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 13it [00:00, 272.26it/s, center_shift=0.044255, iteration=14, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 14it [00:00, 272.67it/s, center_shift=0.070216, iteration=15, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 15it [00:00, 273.84it/s, center_shift=0.344136, iteration=16, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 16it [00:00, 275.47it/s, center_shift=0.290831, iteration=17, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 18it [00:00, 282.95it/s, center_shift=0.000000, iteration=18, tol=0.000100]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=1140.818481, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 140.99it/s, center_shift=44.733231, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 181.23it/s, center_shift=25.894604, iteration=3, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 3it [00:00, 194.18it/s, center_shift=12.919411, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 4it [00:00, 201.70it/s, center_shift=11.507927, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 208.85it/s, center_shift=0.063971, iteration=6, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 6it [00:00, 214.08it/s, center_shift=0.167965, iteration=7, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 7it [00:00, 218.87it/s, center_shift=0.186743, iteration=8, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 8it [00:00, 222.38it/s, center_shift=0.681145, iteration=9, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 9it [00:00, 225.68it/s, center_shift=0.559716, iteration=10, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 10it [00:00, 228.37it/s, center_shift=0.281590, iteration=11, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 11it [00:00, 230.67it/s, center_shift=0.100625, iteration=12, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 12it [00:00, 232.21it/s, center_shift=0.141621, iteration=13, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 13it [00:00, 234.06it/s, center_shift=0.448489, iteration=14, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 15it [00:00, 242.82it/s, center_shift=0.000000, iteration=15, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=3370.602783, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 107.33it/s, center_shift=104.334244, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 141.61it/s, center_shift=19.889393, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 3it [00:00, 157.13it/s, center_shift=37.277691, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 4it [00:00, 166.96it/s, center_shift=11.384549, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 171.75it/s, center_shift=2.694604, iteration=6, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 7it [00:00, 195.75it/s, center_shift=0.000000, iteration=7, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=9771.169922, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 73.75it/s, center_shift=110.124626, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 95.63it/s, center_shift=10.160331, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 3it [00:00, 106.07it/s, center_shift=1.302236, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 4it [00:00, 112.60it/s, center_shift=1.781830, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 6it [00:00, 133.88it/s, center_shift=0.000000, iteration=6, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Videos (Width):  60%|██████    | 6/10 [01:38<01:33, 23.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=189.750305, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 157.92it/s, center_shift=9.343554, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 202.13it/s, center_shift=5.344783, iteration=3, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 3it [00:00, 223.86it/s, center_shift=15.996229, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 4it [00:00, 235.30it/s, center_shift=2.106526, iteration=5, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 5it [00:00, 244.70it/s, center_shift=1.155721, iteration=6, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 7it [00:00, 269.36it/s, center_shift=0.000000, iteration=7, tol=0.000100]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=908.942993, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 136.42it/s, center_shift=27.286325, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 173.45it/s, center_shift=11.436441, iteration=3, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 3it [00:00, 192.73it/s, center_shift=5.251940, iteration=4, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 4it [00:00, 206.68it/s, center_shift=0.466225, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 214.52it/s, center_shift=1.011579, iteration=6, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 6it [00:00, 218.66it/s, center_shift=1.363625, iteration=7, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 7it [00:00, 222.75it/s, center_shift=0.258433, iteration=8, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 8it [00:00, 224.60it/s, center_shift=0.586883, iteration=9, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 9it [00:00, 227.37it/s, center_shift=0.545586, iteration=10, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 10it [00:00, 229.45it/s, center_shift=0.055669, iteration=11, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 12it [00:00, 242.09it/s, center_shift=0.000000, iteration=12, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=2484.963379, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 102.43it/s, center_shift=69.300560, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 133.32it/s, center_shift=23.132177, iteration=3, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 3it [00:00, 148.27it/s, center_shift=2.231285, iteration=4, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 5it [00:00, 181.84it/s, center_shift=0.000000, iteration=5, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=6713.841309, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 70.60it/s, center_shift=287.481018, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 92.72it/s, center_shift=37.682331, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 3it [00:00, 100.90it/s, center_shift=37.969372, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 125.66it/s, center_shift=0.000000, iteration=5, tol=0.000100] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Videos (Width):  70%|███████   | 7/10 [02:12<01:20, 26.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=230.468597, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 164.43it/s, center_shift=10.286017, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 211.91it/s, center_shift=1.749592, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 3it [00:00, 234.67it/s, center_shift=0.604805, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 4it [00:00, 245.37it/s, center_shift=1.028258, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 256.59it/s, center_shift=1.692023, iteration=6, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 6it [00:00, 257.35it/s, center_shift=1.679716, iteration=7, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 7it [00:00, 264.51it/s, center_shift=1.070394, iteration=8, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 8it [00:00, 266.68it/s, center_shift=0.484296, iteration=9, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 9it [00:00, 265.17it/s, center_shift=0.061234, iteration=10, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 11it [00:00, 280.66it/s, center_shift=0.000000, iteration=11, tol=0.000100]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=770.531921, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 119.38it/s, center_shift=16.626810, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 155.09it/s, center_shift=10.069311, iteration=3, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 3it [00:00, 177.59it/s, center_shift=0.960586, iteration=4, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 4it [00:00, 189.74it/s, center_shift=0.162304, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 6it [00:00, 218.75it/s, center_shift=0.000000, iteration=6, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=3203.256592, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 101.93it/s, center_shift=136.132462, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 134.52it/s, center_shift=20.140392, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 3it [00:00, 149.81it/s, center_shift=2.994395, iteration=4, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 5it [00:00, 184.06it/s, center_shift=0.000000, iteration=5, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=7068.864258, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 70.19it/s, center_shift=48.080647, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 91.15it/s, center_shift=4.769558, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 3it [00:00, 103.36it/s, center_shift=0.329073, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 130.50it/s, center_shift=0.000000, iteration=5, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Videos (Width):  80%|████████  | 8/10 [02:41<00:54, 27.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=443.979858, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 164.53it/s, center_shift=8.748177, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 205.23it/s, center_shift=1.756175, iteration=3, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 3it [00:00, 225.78it/s, center_shift=1.115261, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 4it [00:00, 231.60it/s, center_shift=0.900914, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 241.81it/s, center_shift=0.572431, iteration=6, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 6it [00:00, 247.34it/s, center_shift=0.595598, iteration=7, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 7it [00:00, 251.70it/s, center_shift=0.094314, iteration=8, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 9it [00:00, 270.00it/s, center_shift=0.000000, iteration=9, tol=0.000100]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=1172.735352, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 132.84it/s, center_shift=47.528881, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 169.93it/s, center_shift=13.774522, iteration=3, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 3it [00:00, 189.90it/s, center_shift=3.441651, iteration=4, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 4it [00:00, 199.12it/s, center_shift=1.686678, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 206.28it/s, center_shift=1.975641, iteration=6, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 6it [00:00, 211.73it/s, center_shift=1.635498, iteration=7, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 8it [00:00, 230.18it/s, center_shift=0.000000, iteration=8, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=3577.828125, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 91.43it/s, center_shift=82.218208, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 125.96it/s, center_shift=8.187290, iteration=3, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 3it [00:00, 144.53it/s, center_shift=3.941617, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 177.27it/s, center_shift=0.000000, iteration=5, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=10377.283203, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 68.43it/s, center_shift=23.981173, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 90.14it/s, center_shift=1.941187, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 4it [00:00, 126.63it/s, center_shift=0.000000, iteration=4, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Videos (Width):  90%|█████████ | 9/10 [03:11<00:28, 28.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=193.987900, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 155.73it/s, center_shift=6.956596, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 198.39it/s, center_shift=1.858677, iteration=3, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 3it [00:00, 222.68it/s, center_shift=2.100240, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 4it [00:00, 236.58it/s, center_shift=0.505365, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 245.91it/s, center_shift=0.019288, iteration=6, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 6it [00:00, 251.39it/s, center_shift=0.013698, iteration=7, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 8it [00:00, 272.32it/s, center_shift=0.000000, iteration=8, tol=0.000100]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=494.594269, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 132.94it/s, center_shift=10.320456, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 171.00it/s, center_shift=0.721472, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 3it [00:00, 185.60it/s, center_shift=0.390723, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 224.96it/s, center_shift=0.000000, iteration=5, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=1737.062744, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 102.13it/s, center_shift=34.940376, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 135.10it/s, center_shift=6.081357, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 3it [00:00, 149.98it/s, center_shift=2.607036, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 4it [00:00, 158.18it/s, center_shift=4.511014, iteration=5, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 163.25it/s, center_shift=0.646058, iteration=6, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 6it [00:00, 168.56it/s, center_shift=2.486021, iteration=7, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 7it [00:00, 173.65it/s, center_shift=9.023144, iteration=8, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 8it [00:00, 176.82it/s, center_shift=0.547890, iteration=9, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 9it [00:00, 178.93it/s, center_shift=0.470930, iteration=10, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 10it [00:00, 180.51it/s, center_shift=0.105356, iteration=11, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 12it [00:00, 192.44it/s, center_shift=0.000000, iteration=12, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[running kmeans]: 0it [00:00, ?it/s]\u001b[A\n",
      "[running kmeans]: 0it [00:00, ?it/s, center_shift=5081.288574, iteration=1, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 1it [00:00, 68.49it/s, center_shift=42.789051, iteration=2, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 2it [00:00, 91.61it/s, center_shift=0.343911, iteration=3, tol=0.000100] \u001b[A\n",
      "[running kmeans]: 3it [00:00, 102.72it/s, center_shift=2.425100, iteration=4, tol=0.000100]\u001b[A\n",
      "[running kmeans]: 5it [00:00, 128.80it/s, center_shift=0.000000, iteration=5, tol=0.000100]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Videos (Width): 100%|██████████| 10/10 [03:38<00:00, 21.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width expansion complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class WidthExpansion:\n",
    "    def __init__(self, config: PipelineConfig):\n",
    "        self.config = config\n",
    "        self.model = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "    def _get_relevance_scores(self, representative_frames, video_id, captions_dict, questions):\n",
    "        # This method now expects a dictionary, which is handled in the calling function\n",
    "        video_captions_list = captions_dict.get(video_id, [])\n",
    "        question_text = questions.get(video_id, \"\")\n",
    "        \n",
    "\n",
    "        # Access captions by list index since we know it's a list\n",
    "        descriptions = []\n",
    "        for idx in representative_frames:\n",
    "            caption = video_captions_list[idx] if 0 <= idx < len(video_captions_list) else 'No caption.'\n",
    "            descriptions.append(f\"Frame {idx}: {caption}\")\n",
    "\n",
    "        system_prompt = \"You are an expert video analyst. Analyze frame descriptions and rate their relevance to answering the specific question.\"\n",
    "        user_prompt = f\"\"\"VIDEO QUESTION: {question_text}\\n\n",
    "FRAME DESCRIPTIONS:\\n{chr(10).join(descriptions)}\\n\n",
    "TASK: Rate each frame's relevance to answering the question on a scale of 1-3 (1=Not relevant, 2=Somewhat, 3=Highly relevant).\\n\n",
    "Provide ONLY the relevance scores in this exact format: frame relevance: [score1, score2, ...]\\n\n",
    "You must provide exactly {len(descriptions)} scores.\"\"\"\n",
    "        print('2')\n",
    "        completion = self.model.chat.completions.create(\n",
    "            model=self.config.GROQ_MODEL,\n",
    "            messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}],\n",
    "            temperature=0.0, max_tokens=1000\n",
    "        )\n",
    "        response_text = completion.choices[0].message.content\n",
    "        \n",
    "        match = re.search(r'\\[([0-9,\\s]+)\\]', response_text)\n",
    "        if match:\n",
    "            scores = [int(x.strip()) for x in match.group(1).split(',') if x.strip().isdigit()]\n",
    "            return scores, completion.usage.total_tokens\n",
    "        return [], 0\n",
    "\n",
    "\n",
    "    def run_for_video(self, video_id: str, questions: dict, captions: list): # Expects a list of tuples\n",
    "        features_path = self.config.FEATURES_DIR / f\"{video_id}.pt\"\n",
    "        if not features_path.exists():\n",
    "            print(f\"[WARN] Features not found for {video_id}, skipping.\")\n",
    "            return\n",
    "\n",
    "        # --- FIX: Convert the list of tuples into a dictionary ---\n",
    "        captions_dict = dict(captions)\n",
    "        # --- END FIX ---\n",
    "\n",
    "        frame_feats = torch.load(features_path).to(self.config.DEVICE)\n",
    "        num_clusters = self.config.INIT_CLUSTER_NUM\n",
    "        all_attempts = []\n",
    "\n",
    "        while num_clusters <= self.config.MAX_CLUSTER_NUM:\n",
    "            cluster_ids, cluster_centers = kmeans(X=frame_feats, num_clusters=num_clusters, distance='cosine', device=self.config.DEVICE)\n",
    "            \n",
    "            cluster_centers = cluster_centers.to(self.config.DEVICE)\n",
    "\n",
    "            representative_frames = []\n",
    "            for i in range(num_clusters):\n",
    "                cluster_indices = torch.where(cluster_ids == i)[0]\n",
    "                if len(cluster_indices) > 0:\n",
    "                    distances = torch.norm(frame_feats[cluster_indices] - cluster_centers[i], dim=1)\n",
    "                    closest_local_idx = torch.argmin(distances).item()\n",
    "                    representative_frames.append(cluster_indices[closest_local_idx].item())\n",
    "            \n",
    "            representative_frames = sorted(list(set(representative_frames)))\n",
    "            # Pass the newly created dictionary to the helper function\n",
    "            scores, tokens = self._get_relevance_scores(representative_frames, video_id, captions_dict, questions)\n",
    "            \n",
    "            high_relevance_count = scores.count(3)\n",
    "            attempt_data = {\n",
    "                'num_clusters': num_clusters,\n",
    "                'representative_frames': representative_frames,\n",
    "                'cluster_assignments': cluster_ids.tolist(),\n",
    "                'frame_relevance': scores,\n",
    "                'high_relevance_count': high_relevance_count,\n",
    "                'tokens_used': tokens\n",
    "            }\n",
    "            all_attempts.append(attempt_data)\n",
    "            \n",
    "            if high_relevance_count >= self.config.RELEVANCE_THRESHOLD:\n",
    "                break\n",
    "            num_clusters *= 2\n",
    "        \n",
    "        if not all_attempts:\n",
    "            print(f\"[WARN] Could not perform clustering for {video_id}.\")\n",
    "            return\n",
    "\n",
    "        final_result = all_attempts[-1]\n",
    "        output_data = {\n",
    "            'video_id': video_id,\n",
    "            'final_result': final_result,\n",
    "            'all_clustering_attempts': all_attempts,\n",
    "            'total_tokens': sum(a['tokens_used'] for a in all_attempts)\n",
    "        }\n",
    "        save_json(output_data, self.config.OUTPUTS_DIR / f'width_expansion_{video_id}.json')\n",
    "        return output_data\n",
    "\n",
    "# Execute Width Expansion\n",
    "print(\"--- Starting Width Expansion (Adaptive Clustering) ---\")\n",
    "width_expander = WidthExpansion(config)\n",
    "for video_id in tqdm(video_ids, desc=\"Processing Videos (Width)\"):\n",
    "    # The 'captions' variable here is the original list of tuples\n",
    "    width_expander.run_for_video(video_id, questions, captions)\n",
    "print(\"Width expansion complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Module 3: Depth Expansion (Hierarchical Clustering)\n",
    "\n",
    "Uses the relevance scores from the previous step to guide a hierarchical clustering process. High-relevance clusters are broken down into more granular sub-clusters to provide more detail to the VLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T04:38:04.792874Z",
     "iopub.status.busy": "2025-08-23T04:38:04.792130Z",
     "iopub.status.idle": "2025-08-23T04:38:04.894808Z",
     "shell.execute_reply": "2025-08-23T04:38:04.893824Z",
     "shell.execute_reply.started": "2025-08-23T04:38:04.792848Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Depth Expansion (Hierarchical Clustering) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos (Depth): 100%|██████████| 10/10 [00:00<00:00, 118.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth expansion complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class DepthExpansion:\n",
    "    def __init__(self, config: PipelineConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def _hierarchical_clustering(self, features, cluster_ids, relevance_scores):\n",
    "        clusters = {i: {} for i in range(max(cluster_ids) + 1)}\n",
    "\n",
    "        for cid in set(cluster_ids):\n",
    "            score = relevance_scores[cid] if cid < len(relevance_scores) else 1\n",
    "            indices = [i for i, x in enumerate(cluster_ids) if x == cid]\n",
    "            if len(indices) < 2 or score == 1:\n",
    "                clusters[cid] = [indices]\n",
    "                continue\n",
    "\n",
    "            sub_features = features[indices]\n",
    "            linked_sub = linkage(sub_features.cpu().numpy(), method='ward')\n",
    "            sub_labels = fcluster(linked_sub, self.config.NUM_SUBCLUSTERS, criterion='maxclust') - 1\n",
    "            \n",
    "            if score == 2:\n",
    "                clusters[cid] = [[indices[j] for j in np.where(sub_labels == i)[0]] for i in range(self.config.NUM_SUBCLUSTERS)]\n",
    "                continue\n",
    "            \n",
    "            # Score == 3: Perform sub-subclustering\n",
    "            sub_sub_clusters = []\n",
    "            for sub_cid in range(self.config.NUM_SUBCLUSTERS):\n",
    "                sub_indices = np.where(sub_labels == sub_cid)[0]\n",
    "                if len(sub_indices) < 2:\n",
    "                    sub_sub_clusters.append([indices[i] for i in sub_indices])\n",
    "                    continue\n",
    "                \n",
    "                subsub_features = sub_features[sub_indices]\n",
    "                linked_subsub = linkage(subsub_features.cpu().numpy(), method='ward')\n",
    "                subsub_labels = fcluster(linked_subsub, self.config.NUM_SUB_SUBCLUSTERS, criterion='maxclust') - 1\n",
    "                for subsub_cid in range(self.config.NUM_SUB_SUBCLUSTERS):\n",
    "                    final_indices = sub_indices[np.where(subsub_labels == subsub_cid)[0]]\n",
    "                    sub_sub_clusters.append([indices[i] for i in final_indices])\n",
    "            clusters[cid] = sub_sub_clusters\n",
    "        return clusters\n",
    "\n",
    "    def _find_closest_points(self, features, clusters):\n",
    "        final_indices = set()\n",
    "        for primary_cluster in clusters.values():\n",
    "            for sub_cluster in primary_cluster:\n",
    "                if not sub_cluster: continue\n",
    "                points = features[torch.tensor(sub_cluster, dtype=torch.long)]\n",
    "                centroid = points.mean(dim=0)\n",
    "                distances = torch.norm(points - centroid, dim=1)\n",
    "                closest_idx = torch.argmin(distances).item()\n",
    "                final_indices.add(sub_cluster[closest_idx])\n",
    "        return sorted(list(final_indices))\n",
    "\n",
    "    def run_for_video(self, video_id: str):\n",
    "        width_results_path = self.config.OUTPUTS_DIR / f'width_expansion_{video_id}.json'\n",
    "        features_path = self.config.FEATURES_DIR / f\"{video_id}.pt\"\n",
    "        if not width_results_path.exists() or not features_path.exists():\n",
    "            return\n",
    "\n",
    "        width_data = load_json(width_results_path)['final_result']\n",
    "        features = torch.load(features_path)\n",
    "\n",
    "        clusters = self._hierarchical_clustering(\n",
    "            features, width_data['cluster_assignments'], width_data['frame_relevance'])\n",
    "        \n",
    "        final_frames = self._find_closest_points(features, clusters)\n",
    "\n",
    "        output_data = {\n",
    "            \"video_id\": video_id,\n",
    "            \"original_representative_frames\": width_data['representative_frames'],\n",
    "            \"final_representative_frames\": final_frames\n",
    "        }\n",
    "        save_json(output_data, self.config.OUTPUTS_DIR / f'depth_expansion_{video_id}.json')\n",
    "        return output_data\n",
    "\n",
    "# Execute Depth Expansion\n",
    "print(\"--- Starting Depth Expansion (Hierarchical Clustering) ---\")\n",
    "depth_expander = DepthExpansion(config)\n",
    "for video_id in tqdm(video_ids, desc=\"Processing Videos (Depth)\"):\n",
    "    depth_expander.run_for_video(video_id)\n",
    "print(\"Depth expansion complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T04:38:04.896040Z",
     "iopub.status.busy": "2025-08-23T04:38:04.895735Z",
     "iopub.status.idle": "2025-08-23T04:38:04.985009Z",
     "shell.execute_reply": "2025-08-23T04:38:04.984227Z",
     "shell.execute_reply.started": "2025-08-23T04:38:04.896005Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed 00f93e1e-cf4e-4835-88b4-4ad68216e86f → saved /kaggle/working/filtered_jsons_thresholded/00f93e1e-cf4e-4835-88b4-4ad68216e86f_thresholded.json\n",
      "✅ Processed 0074f737-11cb-497d-8d07-77c3a8127391 → saved /kaggle/working/filtered_jsons_thresholded/0074f737-11cb-497d-8d07-77c3a8127391_thresholded.json\n",
      "✅ Processed 01a144a5-24d2-4a5a-af01-1f318d674bed → saved /kaggle/working/filtered_jsons_thresholded/01a144a5-24d2-4a5a-af01-1f318d674bed_thresholded.json\n",
      "✅ Processed 02925d7a-a5db-4127-8c31-b232e78b684d → saved /kaggle/working/filtered_jsons_thresholded/02925d7a-a5db-4127-8c31-b232e78b684d_thresholded.json\n",
      "✅ Processed 03657401-d4a4-40d0-9b03-d7e093ef93d1 → saved /kaggle/working/filtered_jsons_thresholded/03657401-d4a4-40d0-9b03-d7e093ef93d1_thresholded.json\n",
      "✅ Processed 00b9a0de-c59e-49cb-a127-6081e2fb8c8e → saved /kaggle/working/filtered_jsons_thresholded/00b9a0de-c59e-49cb-a127-6081e2fb8c8e_thresholded.json\n",
      "✅ Processed 026a2f15-c454-4c28-80e0-24c85d7f4ecf → saved /kaggle/working/filtered_jsons_thresholded/026a2f15-c454-4c28-80e0-24c85d7f4ecf_thresholded.json\n",
      "✅ Processed 0437cf5f-5014-47d6-b4b3-f299380aa688 → saved /kaggle/working/filtered_jsons_thresholded/0437cf5f-5014-47d6-b4b3-f299380aa688_thresholded.json\n",
      "✅ Processed 00faf954-74f7-4aa3-8b29-4a5dff4f9518 → saved /kaggle/working/filtered_jsons_thresholded/00faf954-74f7-4aa3-8b29-4a5dff4f9518_thresholded.json\n",
      "✅ Processed 011b8b73-0ce4-4843-95ef-33b79610d212 → saved /kaggle/working/filtered_jsons_thresholded/011b8b73-0ce4-4843-95ef-33b79610d212_thresholded.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- Config ---\n",
    "features_dir = \"/kaggle/working/extracted_features\"\n",
    "json_dir = \"/kaggle/working/outputs\"\n",
    "output_dir = \"/kaggle/working/filtered_jsons_thresholded\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "threshold = 0.8  # cosine similarity threshold\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# --- Loop over all .pt feature files ---\n",
    "for feat_file in os.listdir(features_dir):\n",
    "    if not feat_file.endswith(\".pt\"):\n",
    "        continue\n",
    "\n",
    "    # Extract video ID from filename\n",
    "    video_id = os.path.splitext(feat_file)[0]  # e.g. \"0074f737-11cb-497d-8d07-77c3a8127391\"\n",
    "\n",
    "    # Load features\n",
    "    feat_path = os.path.join(features_dir, feat_file)\n",
    "    frame_features = torch.load(feat_path)  # shape: [num_frames, 1024]\n",
    "\n",
    "    # Load corresponding JSON\n",
    "    json_filename = f\"depth_expansion_{video_id}.json\"\n",
    "    json_path = os.path.join(json_dir, json_filename)\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"⚠️ JSON not found for {video_id}, skipping...\")\n",
    "        continue\n",
    "\n",
    "    data = load_json(json_path)\n",
    "    indices = data.get(\"final_representative_frames\", [])\n",
    "\n",
    "    # --- Apply threshold filtering ---\n",
    "    filtered_indices = []\n",
    "    if indices:\n",
    "        filtered_indices.append(indices[0])\n",
    "        ref_idx = indices[0]\n",
    "\n",
    "        for next_idx in indices[1:]:\n",
    "            sim = F.cosine_similarity(\n",
    "                frame_features[ref_idx].unsqueeze(0),\n",
    "                frame_features[next_idx].unsqueeze(0)\n",
    "            ).item()\n",
    "\n",
    "            if sim < threshold:\n",
    "                filtered_indices.append(next_idx)\n",
    "\n",
    "            ref_idx = next_idx  # update reference\n",
    "\n",
    "    # --- Save new JSON ---\n",
    "    out_data = {\"final_representative_frames\": filtered_indices}\n",
    "    out_path = os.path.join(output_dir, f\"{video_id}_thresholded.json\")\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump(out_data, f, indent=2)\n",
    "\n",
    "    print(f\"✅ Processed {video_id} → saved {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T04:38:04.985981Z",
     "iopub.status.busy": "2025-08-23T04:38:04.985762Z",
     "iopub.status.idle": "2025-08-23T04:38:04.993561Z",
     "shell.execute_reply": "2025-08-23T04:38:04.992783Z",
     "shell.execute_reply.started": "2025-08-23T04:38:04.985962Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'final_representative_frames': [3,\n",
       "  15,\n",
       "  20,\n",
       "  32,\n",
       "  36,\n",
       "  40,\n",
       "  44,\n",
       "  63,\n",
       "  65,\n",
       "  70,\n",
       "  71,\n",
       "  73,\n",
       "  100,\n",
       "  105,\n",
       "  122,\n",
       "  154,\n",
       "  165,\n",
       "  177]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = load_json('/kaggle/working/filtered_jsons_thresholded/0074f737-11cb-497d-8d07-77c3a8127391_thresholded.json')\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Module 4: VLM Question Answering\n",
    "\n",
    "Loads a powerful Vision-Language Model. It processes the question along with the refined set of keyframes from the depth expansion step to generate a final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T04:38:04.994664Z",
     "iopub.status.busy": "2025-08-23T04:38:04.994437Z",
     "iopub.status.idle": "2025-08-23T04:38:05.010121Z",
     "shell.execute_reply": "2025-08-23T04:38:05.009353Z",
     "shell.execute_reply.started": "2025-08-23T04:38:04.994639Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def most_frequent_choice(text, letter_to_num=None):\n",
    "    if letter_to_num is None:\n",
    "        letter_to_num = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5}\n",
    "\n",
    "    # Extract lines and letters\n",
    "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "    letters = []\n",
    "    for ln in lines:\n",
    "        m = re.match(r'^([A-Z])\\.', ln, flags=re.I)\n",
    "        if m:\n",
    "            letters.append(m.group(1).upper())\n",
    "\n",
    "    # Find most frequent letter\n",
    "    if not letters:\n",
    "        return None, None\n",
    "\n",
    "    most_letter, freq = Counter(letters).most_common(1)[0]\n",
    "    most_num = letter_to_num.get(most_letter)\n",
    "\n",
    "    return most_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T04:38:05.011094Z",
     "iopub.status.busy": "2025-08-23T04:38:05.010904Z",
     "iopub.status.idle": "2025-08-23T04:38:05.023815Z",
     "shell.execute_reply": "2025-08-23T04:38:05.022935Z",
     "shell.execute_reply.started": "2025-08-23T04:38:05.011079Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load answer\n",
    "subest_json_path = '/kaggle/working/videotree/subset_answers.json'\n",
    "answer = load_json(subest_json_path)\n",
    "answer['0074f737-11cb-497d-8d07-77c3a8127391']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T04:38:05.026434Z",
     "iopub.status.busy": "2025-08-23T04:38:05.026095Z",
     "iopub.status.idle": "2025-08-23T04:44:44.055006Z",
     "shell.execute_reply": "2025-08-23T04:44:44.054201Z",
     "shell.execute_reply.started": "2025-08-23T04:38:05.026413Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting VLM Question Answering ---\n",
      "\n",
      "==================== Final Result for Video: 00b9a0de-c59e-49cb-a127-6081e2fb8c8e ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n",
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/modeling_auto.py:2199: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLM model loaded.\n",
      "Most common letter(s): 5\n",
      "\n",
      "❓ QUESTION:\n",
      "Question:\n",
      "What was the primary purpose of the cup of water in this video, and how did it contribute to the overall painting process?\n",
      "\n",
      "Options:\n",
      "A. To provide a source of water for the paintbrush.\n",
      "B. To provide a place to store the paintbrush.\n",
      "C. To provide a place to dispose of the paintbrush.\n",
      "D. To provide a place to rest the paintbrush.\n",
      "E. To clean the paintbrush.\n",
      "\n",
      "Please choose the most appropriate answer (A–E).\n",
      "\n",
      "🧠 MODEL ANSWER:\n",
      "E. To clean the paintbrush.\n",
      "\n",
      "✅ Ground Truth Answer:\n",
      "5\n",
      "\n",
      "==================== Final Result for Video: 0074f737-11cb-497d-8d07-77c3a8127391 ====================\n",
      "Most common letter(s): 4\n",
      "\n",
      "❓ QUESTION:\n",
      "Question:\n",
      "Taking into account all the actions performed by c, what can you deduce about the primary objective and focus within the video content?\n",
      "\n",
      "Options:\n",
      "A. C is cooking.\n",
      "B. C is doing laundry.\n",
      "C. C is cleaning the kitchen.\n",
      "D. C is cleaning dishes.\n",
      "E. C is cleaning the bathroom.\n",
      "\n",
      "Please choose the most appropriate answer (A–E).\n",
      "\n",
      "🧠 MODEL ANSWER:\n",
      "D. C is cleaning dishes.\n",
      "D. C is cleaning dishes.\n",
      "\n",
      "✅ Ground Truth Answer:\n",
      "4\n",
      "\n",
      "==================== Final Result for Video: 011b8b73-0ce4-4843-95ef-33b79610d212 ====================\n",
      "Most common letter(s): 4\n",
      "\n",
      "❓ QUESTION:\n",
      "Question:\n",
      "What can be deduced about c's level of expertise in the task by observing the kind of adjustments made throughout the video?\n",
      "\n",
      "Options:\n",
      "A. C is a novice woodworker. he was not able to cut the wood to size and install it on the wall without making several adjustments.\n",
      "B. C is an expert woodworker. he was able to cut the wood to size and install it on the wall without making any adjustments.\n",
      "C. C is a professional woodworker. he was able to cut the wood to size and install it on the wall in a timely and efficient manner.\n",
      "D. C is an experienced woodworker. he was able to cut the wood to size and install it on the wall with few adjustments.\n",
      "E. C is an amateur woodworker. he was able to cut the wood to size and install it on the wall, but he took a long time to do so.\n",
      "\n",
      "Please choose the most appropriate answer (A–E).\n",
      "\n",
      "🧠 MODEL ANSWER:\n",
      "D. C is an experienced woodworker. he was able to cut the wood to size and install it on the wall with few adjustments.\n",
      "D. C is an experienced woodworker. he was able to cut the wood to size and install it on the wall with few adjustments.\n",
      "D. C is an experienced woodworker. he was able to cut the wood to size and install it on the wall with few adjustments.\n",
      "\n",
      "✅ Ground Truth Answer:\n",
      "4\n",
      "\n",
      "==================== Final Result for Video: 026a2f15-c454-4c28-80e0-24c85d7f4ecf ====================\n",
      "Most common letter(s): 2\n",
      "\n",
      "❓ QUESTION:\n",
      "Question:\n",
      "Considering the sequence of events, what can be inferred about the importance of precision and accuracy in the character's actions, and how is this demonstrated within the video?\n",
      "\n",
      "Options:\n",
      "A. Precision and accuracy are important in the character's actions because they ensure that the wood is cut in a straight line.\n",
      "B. Precision and accuracy are incredibly important in the character's actions, as they ensure that the wood is cut evenly and consistently.\n",
      "C. In the character's actions, precision and accuracy are extremely important since they guarantee that the wood is cut safely and efficiently.\n",
      "D. Precision and accuracy are important in the character's actions because they ensure that the wood is cut to the correct size.\n",
      "E. Precision and accuracy are crucial in the character's actions since they ensure that the wood is cut efficiently and quickly.\n",
      "\n",
      "Please choose the most appropriate answer (A–E).\n",
      "\n",
      "🧠 MODEL ANSWER:\n",
      "B. Precision and accuracy are incredibly important in the character's actions, as they ensure that the wood is cut evenly and consistently.\n",
      "C. In the character's actions, precision and accuracy are extremely important since they guarantee that the wood is cut safely and efficiently.\n",
      "\n",
      "✅ Ground Truth Answer:\n",
      "4\n",
      "\n",
      "==================== Final Result for Video: 00f93e1e-cf4e-4835-88b4-4ad68216e86f ====================\n",
      "Most common letter(s): (None, None)\n",
      "\n",
      "❓ QUESTION:\n",
      "Question:\n",
      "What is the overarching theme of the video, considering the activities performed by both characters?\n",
      "\n",
      "Options:\n",
      "A. The overarching central theme presented in the video is that individuals can be both sociable and independent simultaneously. the visual content demonstrates that it is entirely possible to be both connected to others meaningfully and to savor solitary moments, emphasizing that it is crucial to find a harmonious balance between these two aspects.\n",
      "B. The overarching theme of the video is that people can be both engaged in challenging activities and enjoying leisurely activities at the same time. the video shows that it is possible to be both productive and relaxed, and that it is important to find a balance between the two.\n",
      "C. The primary, overarching theme presented in the video emphasizes that individuals can truly be both creative and practical simultaneously. the enlightening video demonstrates the realistic possibility of being both highly imaginative and remarkably efficient, while stressing the significance of discovering an equilibrium between these two essential aspects.\n",
      "D. The overarching theme of the video is that people can be both ambitious and humble. the video shows that it is possible to be both driven and modest, and that it is important to find a balance between the two.\n",
      "E. The primary overarching theme presented in the video is that individuals can simultaneously possess and exhibit both intelligence and emotional aspects. effectively, the video demonstrates that the coexistence of rational and intuitive qualities is feasible, emphasizing the significance of establishing equilibrium between these two crucial elements.\n",
      "\n",
      "Please choose the most appropriate answer (A–E).\n",
      "\n",
      "🧠 MODEL ANSWER:\n",
      "B\n",
      "A\n",
      "\n",
      "✅ Ground Truth Answer:\n",
      "2\n",
      "\n",
      "==================== Final Result for Video: 00faf954-74f7-4aa3-8b29-4a5dff4f9518 ====================\n",
      "Most common letter(s): 5\n",
      "\n",
      "❓ QUESTION:\n",
      "Question:\n",
      "What is the primary sequence of actions performed by c throughout the video, and how do these actions relate to the overall task being performed?\n",
      "\n",
      "Options:\n",
      "A. C cleans brick mold with his hand.\n",
      "B. C scoops clay into the brick mold, removes clay from the brick mold, scoops mortar from a pile of mortar on the floor, slams mortar into the brick mold, scoops excess mortar from the brick mold, throws excess mortar on the pile of mortar in his front, adds clay from the floor on the brick mold, and drops brick from brick mold beside already made bricks on the floor. then, c cleans brick mold with his hand.\n",
      "C. C scoops clay into the brick mold, removes clay from the brick mold, scoops mortar from a pile of mortar on the floor, slams mortar into the brick mold, scoops excess mortar from the brick mold, throws excess mortar on the pile of mortar in his front, adds clay from the floor on the brick mold, drops brick from brick mold beside already made bricks on the floor. then, c takes a break.\n",
      "D. C scoops clay into the brick mold, removes clay from the brick mold, scoops mortar from a pile of mortar on the floor, slams mortar into the brick mold, scoops excess mortar from the brick mold, throws excess mortar on the pile of mortar in his front, adds clay from the floor on the brick mold, drops brick from brick mold beside already made bricks on the floor. then, c goes to sleep.\n",
      "E. C scoops clay into the brick mold, removes clay from the brick mold, scoops mortar from a pile of mortar on the floor, slams mortar into the brick mold, scoops excess mortar from the brick mold, throws excess mortar on the pile of mortar in his front, adds clay from the floor on the brick mold, and drops brick from brick mold beside already made bricks on the floor.\n",
      "\n",
      "Please choose the most appropriate answer (A–E).\n",
      "\n",
      "🧠 MODEL ANSWER:\n",
      "E. C scoops clay into the brick mold, removes clay from the brick mold, scoops mortar from a pile of mortar on the floor, slams mortar into the brick mold, scoops excess mortar from the brick mold, throws excess mortar\n",
      "E. C scoops clay into the brick mold, removes clay from the brick mold, scoops mortar from a pile of mortar on the floor, slams mortar into the brick mold, scoops excess mortar from the brick mold, throws excess mortar\n",
      "\n",
      "✅ Ground Truth Answer:\n",
      "5\n",
      "\n",
      "==================== Final Result for Video: 03657401-d4a4-40d0-9b03-d7e093ef93d1 ====================\n",
      "Most common letter(s): 4\n",
      "\n",
      "❓ QUESTION:\n",
      "Question:\n",
      "Based on the video, what crucial points indicate a change in c's approach to knife sharpening and handling? explain their significance in relation to the video's overall goal.\n",
      "\n",
      "Options:\n",
      "A. The crucial points that indicate a change in c's approach to knife sharpening and handling are when they first check the knife, when they adjust the electric knife sharpener, and when they wrap the towel around the knife. these points show that c is becoming more careful and precise in their knife sharpening process.\n",
      "B. The crucial points that indicate a change in c's approach to knife sharpening and handling are when they first check the knife, when they sharpen the knife on a whetstone, and when they check the knife again. these points show that c is becoming more experienced in their knife sharpening process.\n",
      "C. The crucial points that indicate a significant change in c's approach to knife sharpening and handling arise when they initially examine the knife, when they expertly sharpen the knife on a honing steel, and when they carefully check the knife again for sharpness. these particular points demonstrate that c is gradually becoming more confident in mastering their knife sharpening process.\n",
      "D. The crucial points that indicate a significant change in c's approach to knife sharpening and handling techniques are when they first carefully check the knife, thoroughly sharpen it using a ceramic knife sharpener, and attentively examine the knife again afterward. these particular points demonstrate that c is gradually becoming more knowledgeable and skilled about knife sharpening methods.\n",
      "E. The crucial points that illustrate a significant change in c's approach to knife sharpening and handling include when they initially inspect the knife, when they sharpen the knife using a manual knife sharpener, and when they thoroughly check the knife again. these essential points clearly demonstrate that c is progressively becoming more skilled in the art of knife sharpening.\n",
      "\n",
      "Please choose the most appropriate answer (A–E).\n",
      "\n",
      "🧠 MODEL ANSWER:\n",
      "D. The crucial points that indicate a significant change in c's approach to knife sharpening and handling techniques are when they first carefully check the knife, thoroughly sharpen it using a ceramic knife sharpener, and attentively examine the knife again afterward. these\n",
      "\n",
      "✅ Ground Truth Answer:\n",
      "1\n",
      "\n",
      "==================== Final Result for Video: 0437cf5f-5014-47d6-b4b3-f299380aa688 ====================\n",
      "Most common letter(s): 1\n",
      "\n",
      "❓ QUESTION:\n",
      "Question:\n",
      "While performing repetitive actions, were there any key deviations that had significant impact on the overall process? explain what was different about them and why they were important in the context of the video.\n",
      "\n",
      "Options:\n",
      "A. While performing repetitive actions, there were no key deviations that had significant impact on the overall process.\n",
      "B. While performing repetitive actions, there was a key deviation that had a significant impact on the overall process. the character accidentally dropped one of the books.\n",
      "C. While performing repetitive actions, there was a key deviation that had a significant impact on the overall process. the character ran out of cleaning supplies.\n",
      "D. While performing repetitive actions, there was a key deviation that had a significant impact on the overall process. the character got tired and had to take a break.\n",
      "E. While performing repetitive actions, there was a key deviation that had a significant impact on the overall process. the character found a book that they were interested in and started reading it.\n",
      "\n",
      "Please choose the most appropriate answer (A–E).\n",
      "\n",
      "🧠 MODEL ANSWER:\n",
      "A. While performing repetitive actions, there were no key deviations that had significant impact on the overall process.\n",
      "A. While performing repetitive actions, there were no key deviations that had significant impact on the overall process.\n",
      "\n",
      "✅ Ground Truth Answer:\n",
      "1\n",
      "\n",
      "==================== Final Result for Video: 02925d7a-a5db-4127-8c31-b232e78b684d ====================\n",
      "Most common letter(s): 5\n",
      "\n",
      "❓ QUESTION:\n",
      "Question:\n",
      "Summarize the most important aspects of c's actions in the video and explain how these key elements contribute to the overall purpose of the activities depicted.\n",
      "\n",
      "Options:\n",
      "A. The most important aspects of c's actions in the video are that he is wiping his face. this action is important because it is necessary to keep c's face clean.\n",
      "B. The most important aspects of c's actions in the video are that he is breaking concrete and cleaning the wooden bench. these actions are important because they are necessary to complete the task of repairing the wooden bench.\n",
      "C. The most important aspects of c's actions in the video are that he is holding his shirt. this action is important because it is necessary to keep c's shirt from getting dirty.\n",
      "D. The most important aspects of c's actions in the video are that he is walking towards the wooden bench. this action is important because it is necessary to get to the wooden bench so that c can start cleaning it.\n",
      "E. The most important aspects of c's actions in the video are that he is picking up the plastic bowl plate and the brush. these actions are important because they are necessary to get the tools that c needs to clean the wooden bench.\n",
      "\n",
      "Please choose the most appropriate answer (A–E).\n",
      "\n",
      "🧠 MODEL ANSWER:\n",
      "E. The most important aspects of c's actions in the video are that he is picking up the plastic bowl plate and the brush. these actions are important because they are necessary to get the tools that c needs to clean the wooden bench.\n",
      "\n",
      "✅ Ground Truth Answer:\n",
      "2\n",
      "\n",
      "==================== Final Result for Video: 01a144a5-24d2-4a5a-af01-1f318d674bed ====================\n",
      "Most common letter(s): 5\n",
      "\n",
      "❓ QUESTION:\n",
      "Question:\n",
      "What is the overall purpose of c's actions in this video? how do the actions of the man contribute to this purpose?\n",
      "\n",
      "Options:\n",
      "A. C is trying to build a tower out of tiles. the man's actions contribute to the purpose of the video by providing c with a steady surface to build on.\n",
      "B. C is trying to solve a puzzle. the man's actions contribute to the purpose of the video by providing c with clues to help solve the puzzle.\n",
      "C. C is trying to create a work of art. the man's actions contribute to the purpose of the video by providing c with inspiration and feedback.\n",
      "D. C is trying to teach the man how to play dominoes. the man's actions contribute to the purpose of the video by providing c with a willing student.\n",
      "E. C is playing a game of dominoes with a man. the man's actions contribute to the purpose of the video by providing c with an opponent to play against.\n",
      "\n",
      "Please choose the most appropriate answer (A–E).\n",
      "\n",
      "🧠 MODEL ANSWER:\n",
      "E. C is playing a game of dominoes with a man. the man's actions contribute to the purpose of the video by providing c with an opponent to play against.\n",
      "\n",
      "✅ Ground Truth Answer:\n",
      "5\n",
      "\n",
      "--- Pipeline Finished ---\n",
      "✅ Correct Answers: 6/10 (60.00% accuracy)\n"
     ]
    }
   ],
   "source": [
    "class VLMInference:\n",
    "    def __init__(self, config: PipelineConfig):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.processor = None\n",
    "\n",
    "    def _load_model(self):\n",
    "        if self.model is not None and self.processor is not None:\n",
    "            return\n",
    "        \n",
    "        self.processor = AutoProcessor.from_pretrained(self.config.VLM_MODEL_ID, trust_remote_code=True)\n",
    "        self.model = AutoModelForVision2Seq.from_pretrained(\n",
    "            self.config.VLM_MODEL_ID,\n",
    "            trust_remote_code=True,\n",
    "            low_cpu_mem_usage=True,\n",
    "            device_map=\"auto\"\n",
    "        ).eval()\n",
    "        print(\"VLM model loaded.\")\n",
    "\n",
    "    def clear_memory(self):\n",
    "        del self.model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "\n",
    "    def _extract_frames_at_1fps(self, video_path: Path) -> dict[int, Image.Image]:\n",
    "        cap = cv2.VideoCapture(str(video_path))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "        \n",
    "        frames = {}\n",
    "        frame_idx, saved_idx = 0, 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "            if frame_idx % int(fps) == 0:\n",
    "                frames[saved_idx] = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "                saved_idx += 1\n",
    "            frame_idx += 1\n",
    "        cap.release()\n",
    "        return frames\n",
    "\n",
    "    def run_for_video(self, video_id: str, question: str):\n",
    "        self._load_model()\n",
    "        # depth_results_path = self.config.OUTPUTS_DIR / f'depth_expansion_{video_id}.json'\n",
    "        t_out = \"/kaggle/working/filtered_jsons_thresholded\"\n",
    "        depth_results_path = os.path.join(t_out, f\"{video_id}_thresholded.json\")\n",
    "        video_path = self.config.VIDEO_DIR / f\"{video_id}.mp4\"\n",
    "\n",
    "        # if not depth_results_path.exists():\n",
    "        #     print(f\"[WARN] Depth expansion results not found for {video_id}\")\n",
    "        #     return None\n",
    "            \n",
    "        depth_data = load_json(depth_results_path)\n",
    "        keyframe_indices = depth_data['final_representative_frames']\n",
    "        \n",
    "        # The indices from feature extraction correspond to frames extracted at ~1 FPS\n",
    "        all_frames = self._extract_frames_at_1fps(video_path)\n",
    "        keyframe_images = [all_frames[i] for i in keyframe_indices if i in all_frames]\n",
    "        \n",
    "        if not keyframe_images:\n",
    "            print(f\"[WARN] No keyframe images found for {video_id}\")\n",
    "            return None\n",
    "            \n",
    "        # Batch processing for memory efficiency\n",
    "        answers = []\n",
    "        for i in range(0, len(keyframe_images), self.config.VLM_BATCH_SIZE):\n",
    "            batch_images = keyframe_images[i:i + self.config.VLM_BATCH_SIZE]\n",
    "            content = [{\"type\": \"image\", \"image\": img} for img in batch_images]\n",
    "            content.append({\"type\": \"text\", \"text\": question})\n",
    "            messages = [{\"role\": \"user\", \"content\": content}]\n",
    "            \n",
    "            try:\n",
    "                inputs = self.processor.apply_chat_template(\n",
    "                    messages, add_generation_prompt=True, tokenize=True,\n",
    "                    return_dict=True, return_tensors=\"pt\"\n",
    "                ).to(self.model.device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model.generate(**inputs, max_new_tokens=50)\n",
    "                \n",
    "                answer = self.processor.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
    "                answers.append(answer.strip())\n",
    "\n",
    "            except torch.cuda.OutOfMemoryError:\n",
    "                print(f\"[WARN] CUDA OOM on video {video_id}, batch {i}. Skipping batch.\")\n",
    "            finally:\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "        return \"\\n\".join(answers)\n",
    "\n",
    "\n",
    "# Execute VLM Inference and Display Final Results\n",
    "print(\"--- Starting VLM Question Answering ---\")\n",
    "vlm = VLMInference(config)\n",
    "correct_count = 0\n",
    "total_count = 0\n",
    "\n",
    "for video_id in video_ids:\n",
    "    print(f\"\\n{'='*20} Final Result for Video: {video_id} {'='*20}\")\n",
    "    question_text = questions.get(video_id, \"No question available.\")\n",
    "    final_answer = vlm.run_for_video(video_id, question_text)\n",
    "    choices = most_frequent_choice(final_answer)\n",
    "    print(\"Most common letter(s):\", choices)\n",
    "\n",
    "    ground_truth = answer[video_id] + 1\n",
    "\n",
    "    # Count total and correct answers\n",
    "    total_count += 1\n",
    "    if ground_truth ==choices:\n",
    "        correct_count += 1\n",
    "\n",
    "    print(f\"\\n❓ QUESTION:\\n{question_text}\")\n",
    "    print(f\"\\n🧠 MODEL ANSWER:\\n{final_answer if final_answer else 'Could not generate an answer.'}\")\n",
    "    print(f\"\\n✅ Ground Truth Answer:\\n{ground_truth}\")\n",
    "\n",
    "# Final report\n",
    "accuracy = (correct_count / total_count * 100) if total_count > 0 else 0\n",
    "print(\"\\n--- Pipeline Finished ---\")\n",
    "print(f\"✅ Correct Answers: {correct_count}/{total_count} ({accuracy:.2f}% accuracy)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13475297,
     "datasetId": 7997229,
     "sourceId": 12840520,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
